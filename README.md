This project develops an Explainable AI (XAI) framework for detecting potential Adverse Drug Reactions (ADRs) using machine learning models and explainability techniques. The goal is not only to predict ADRs but also to interpret the modelâ€™s decisions through LIME, SHAP, Integrated Gradients, Partial Dependence Plots and TreeInterpreter.
The following steps were performed:
- Built machine learning models for ADR prediction
- Applied explainability methods to interpret model predictions
- Evaluated explanations using faithfulness, fidelity, and complexity metrics
- Provided insights for healthcare researchers and clinicians through interpretable AI
